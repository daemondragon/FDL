{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2270,
     "status": "ok",
     "timestamp": 1573606004254,
     "user": {
      "displayName": "Benoit FrÃ©dÃ©ric-Moreau",
      "photoUrl": "",
      "userId": "09939474294080590706"
     },
     "user_tz": -60
    },
    "id": "XfkBZ2f9J_20",
    "outputId": "287a12b2-840a-4b29-c37f-b48b495e2c4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/beuvry_j/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LSTM, Dropout, Dense, Bidirectional,  Flatten, Input, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords=stopwords.words('english')\n",
    "\n",
    "T = TweetTokenizer()\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
    "EMBEDDING_FILE = '../GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tpo2LX6hJ_vg"
   },
   "outputs": [],
   "source": [
    "def value_sentiment(x):\n",
    "  if x == \"neutral\":\n",
    "    return 0\n",
    "  if x == \"positive\":\n",
    "    return 1\n",
    "  if x == \"negative\":\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6d-_t2NKvQp"
   },
   "outputs": [],
   "source": [
    "def onehot (tweets,length):\n",
    "  onh = []\n",
    "  for tweet in tweets:\n",
    "      onh_seq = np.zeros(length) \n",
    "      for i in tweet:\n",
    "        onh_seq[i -1] = 1\n",
    "      onh.append(onh_seq)\n",
    "  return onh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TlSZY2t6J_gj"
   },
   "outputs": [],
   "source": [
    "#replace emojy\n",
    "emojis = {\n",
    "    u\":â€‘\\)\":\"â˜ºï¸\",\n",
    "    u\":\\)\":\"â˜ºï¸\",\n",
    "    u\":-\\]\":\"â˜ºï¸\",\n",
    "    u\":\\]\":\"â˜ºï¸\",\n",
    "    u\":-3\":\"â˜ºï¸\",\n",
    "    u\":3\":\"â˜ºï¸\",\n",
    "    u\":->\":\"â˜ºï¸\",\n",
    "    u\":>\":\"â˜ºï¸\",\n",
    "    u\"8-\\)\":\"â˜ºï¸\",\n",
    "    u\":o\\)\":\"â˜ºï¸\",\n",
    "    u\":-\\}\":\"â˜ºï¸\",\n",
    "    u\":\\}\":\"â˜ºï¸\",\n",
    "    u\":-\\)\":\"â˜ºï¸\",\n",
    "    u\":c\\)\":\"â˜ºï¸\",\n",
    "    u\":\\^\\)\":\"â˜ºï¸\",\n",
    "    u\"=\\]\":\"â˜ºï¸\",\n",
    "    u\"=\\)\":\"â˜ºï¸\",\n",
    "    u\":â€‘D\":\"ğŸ˜ƒ\",\n",
    "    u\":D\":\"ğŸ˜ƒ\",\n",
    "    u\"8â€‘D\":\"ğŸ˜ƒ\",\n",
    "    u\"8D\":\"ğŸ˜ƒ\",\n",
    "    u\"Xâ€‘D\":\"ğŸ˜ƒ\",\n",
    "    u\"XD\":\"ğŸ˜ƒ\",\n",
    "    u\"=D\":\"ğŸ˜ƒ\",\n",
    "    u\"=3\":\"ğŸ˜ƒ\",\n",
    "    u\"B\\^D\":\"ğŸ˜ƒ\",\n",
    "    u\":-\\)\\)\":\"ğŸ˜ƒ\",\n",
    "    u\":â€‘\\(\":\"â˜¹ï¸\",\n",
    "    u\":-\\(\":\"â˜¹ï¸\",\n",
    "    u\":\\(\":\"â˜¹ï¸\",\n",
    "    u\":â€‘c\":\"â˜¹ï¸\",\n",
    "    u\":c\":\"â˜¹ï¸\",\n",
    "    u\":â€‘<\":\"â˜¹ï¸\",\n",
    "    u\":<\":\"â˜¹ï¸\",\n",
    "    u\":â€‘\\[\":\"â˜¹ï¸\",\n",
    "    u\":\\[\":\"â˜¹ï¸\",\n",
    "    u\":-\\|\\|\":\"â˜¹ï¸\",\n",
    "    u\">:\\[\":\"â˜¹ï¸\",\n",
    "    u\":\\{\":\"â˜¹ï¸\",\n",
    "    u\":@\":\"â˜¹ï¸\",\n",
    "    u\">:\\(\":\"â˜¹ï¸\",\n",
    "    u\":'â€‘\\(\":\"ğŸ˜­\",\n",
    "    u\":'\\(\":\"ğŸ˜­\",\n",
    "    u\":'â€‘\\)\":\"ğŸ˜ƒ\",\n",
    "    u\":'\\)\":\"ğŸ˜ƒ\",\n",
    "    u\"Dâ€‘':\":\"ğŸ˜¨\",\n",
    "    u\"D:<\":\"ğŸ˜¨\",\n",
    "    u\"D:\":\"ğŸ˜§\",\n",
    "    u\"D8\":\"ğŸ˜§\",\n",
    "    u\"D;\":\"ğŸ˜§\",\n",
    "    u\"D=\":\"ğŸ˜§\",\n",
    "    u\"DX\":\"ğŸ˜§\",\n",
    "    u\":â€‘O\":\"ğŸ˜®\",\n",
    "    u\":O\":\"ğŸ˜®\",\n",
    "    u\":â€‘o\":\"ğŸ˜®\",\n",
    "    u\":o\":\"ğŸ˜®\",\n",
    "    u\":-0\":\"ğŸ˜®\",\n",
    "    u\"8â€‘0\":\"ğŸ˜®\",\n",
    "    u\">:O\":\"ğŸ˜®\",\n",
    "    u\":-\\*\":\"ğŸ˜—\",\n",
    "    u\":\\*\":\"ğŸ˜—\",\n",
    "    u\":X\":\"ğŸ˜—\",\n",
    "    u\";â€‘\\)\":\"ğŸ˜‰\",\n",
    "    u\";\\)\":\"ğŸ˜‰\",\n",
    "    u\"\\*-\\)\":\"ğŸ˜‰\",\n",
    "    u\"\\*\\)\":\"ğŸ˜‰\",\n",
    "    u\";â€‘\\]\":\"ğŸ˜‰\",\n",
    "    u\";\\]\":\"ğŸ˜‰\",\n",
    "    u\";\\^\\)\":\"ğŸ˜‰\",\n",
    "    u\":â€‘,\":\"ğŸ˜‰\",\n",
    "    u\";D\":\"ğŸ˜‰\",\n",
    "    u\":â€‘P\":\"ğŸ˜›\",\n",
    "    u\":P\":\"ğŸ˜›\",\n",
    "    u\"Xâ€‘P\":\"ğŸ˜›\",\n",
    "    u\"XP\":\"ğŸ˜›\",\n",
    "    u\":â€‘Ã\":\"ğŸ˜›\",\n",
    "    u\":Ã\":\"ğŸ˜›\",\n",
    "    u\":b\":\"ğŸ˜›\",\n",
    "    u\"d:\":\"ğŸ˜›\",\n",
    "    u\"=p\":\"ğŸ˜›\",\n",
    "    u\">:P\":\"ğŸ˜›\",\n",
    "    u\":â€‘/\":\"ğŸ˜•\",\n",
    "    u\":/\":\"ğŸ˜•\",\n",
    "    u\":-[.]\":\"ğŸ˜•\",\n",
    "    u\">:[(\\\\\\)]\":\"ğŸ˜•\",\n",
    "    u\">:/\":\"ğŸ˜•\",\n",
    "    u\":[(\\\\\\)]\":\"ğŸ˜•\",\n",
    "    u\"=/\":\"ğŸ˜•\",\n",
    "    u\"=[(\\\\\\)]\":\"ğŸ˜•\",\n",
    "    u\":L\":\"ğŸ˜•\",\n",
    "    u\"=L\":\"ğŸ˜•\",\n",
    "    u\":S\":\"ğŸ˜•\",\n",
    "    u\":â€‘\\|\":\"ğŸ˜\",\n",
    "    u\":\\|\":\"ğŸ˜\",\n",
    "    u\":$\":\"ğŸ˜³\",\n",
    "    u\":â€‘x\":\"ğŸ¤\",\n",
    "    u\":x\":\"ğŸ¤\",\n",
    "    u\":â€‘#\":\"ğŸ¤\",\n",
    "    u\":#\":\"ğŸ¤\",\n",
    "    u\":â€‘&\":\"ğŸ¤\",\n",
    "    u\":&\":\"ğŸ¤\",\n",
    "    u\"O:â€‘\\)\":\"ğŸ˜‡\",\n",
    "    u\"O:\\)\":\"ğŸ˜‡\",\n",
    "    u\"0:â€‘3\":\"ğŸ˜‡\",\n",
    "    u\"0:3\":\"ğŸ˜‡\",\n",
    "    u\"0:â€‘\\)\":\"ğŸ˜‡\",\n",
    "    u\"0:\\)\":\"ğŸ˜‡\",\n",
    "    u\":â€‘b\":\"ğŸ˜›\",\n",
    "    u\"0;\\^\\)\":\"ğŸ˜‡\",\n",
    "    u\">:â€‘\\)\":\"ğŸ˜ˆ\",\n",
    "    u\">:\\)\":\"ğŸ˜ˆ\",\n",
    "    u\"\\}:â€‘\\)\":\"ğŸ˜ˆ\",\n",
    "    u\"\\}:\\)\":\"ğŸ˜ˆ\",\n",
    "    u\"3:â€‘\\)\":\"ğŸ˜ˆ\",\n",
    "    u\"3:\\)\":\"ğŸ˜ˆ\",\n",
    "    u\">;\\)\":\"ğŸ˜ˆ\",\n",
    "    u\"\\|;â€‘\\)\":\"ğŸ˜\",\n",
    "    u\"\\|â€‘O\":\"ğŸ˜\",\n",
    "    u\":â€‘J\":\"ğŸ˜\",\n",
    "    u\"%â€‘\\)\":\"ğŸ˜µ\",\n",
    "    u\"%\\)\":\"ğŸ˜µ\",\n",
    "    u\":-###..\":\"ğŸ¤’\",\n",
    "    u\":###..\":\"ğŸ¤’\",\n",
    "    u\"\\(>_<\\)\":\"ğŸ˜£\",\n",
    "    u\"\\(>_<\\)>\":\"ğŸ˜£\",\n",
    "    u\"\\(';'\\)\":\"ğŸ‘¶\",\n",
    "    u\"\\(\\^\\^>``\":\"ğŸ˜“\",\n",
    "    u\"\\(\\^_\\^;\\)\":\"ğŸ˜“\",\n",
    "    u\"\\(-_-;\\)\":\"ğŸ˜“\",\n",
    "    u\"\\(~_~;\\) \\(ãƒ»\\.ãƒ»;\\)\":\"ğŸ˜“\",\n",
    "    u\"\\(-_-\\)zzz\":\"ğŸ˜´\",\n",
    "    u\"\\(\\^_-\\)\":\"ğŸ˜‰\",\n",
    "    u\"\\(\\(\\+_\\+\\)\\)\":\"ğŸ˜•\",\n",
    "    u\"\\(\\+o\\+\\)\":\"ğŸ˜•\",\n",
    "    u\"\\^_\\^\":\"ğŸ˜ƒ\",\n",
    "    u\"\\(\\^_\\^\\)/\":\"ğŸ˜ƒ\",\n",
    "    u\"\\(\\^O\\^\\)ï¼\":\"ğŸ˜ƒ\",\n",
    "    u\"\\(\\^o\\^\\)ï¼\":\"ğŸ˜ƒ\",\n",
    "    u\"\\(__\\)\":\"ğŸ™‡\",\n",
    "    u\"_\\(\\._\\.\\)_\":\"ğŸ™‡\",\n",
    "    u\"<\\(_ _\\)>\":\"ğŸ™‡\",\n",
    "    u\"<m\\(__\\)m>\":\"ğŸ™‡\",\n",
    "    u\"m\\(__\\)m\":\"ğŸ™‡\",\n",
    "    u\"m\\(_ _\\)m\":\"ğŸ™‡\",\n",
    "    u\"\\('_'\\)\":\"ğŸ˜­\",\n",
    "    u\"\\(/_;\\)\":\"ğŸ˜­\",\n",
    "    u\"\\(T_T\\) \\(;_;\\)\":\"ğŸ˜­\",\n",
    "    u\"\\(;_;\":\"ğŸ˜­\",\n",
    "    u\"\\(;_:\\)\":\"ğŸ˜­\",\n",
    "    u\"\\(;O;\\)\":\"ğŸ˜­\",\n",
    "    u\"\\(:_;\\)\":\"ğŸ˜­\",\n",
    "    u\"\\(ToT\\)\":\"ğŸ˜­\",\n",
    "    u\";_;\":\"ğŸ˜­\",\n",
    "    u\";-;\":\"ğŸ˜­\",\n",
    "    u\";n;\":\"ğŸ˜­\",\n",
    "    u\";;\":\"ğŸ˜­\",\n",
    "    u\"Q\\.Q\":\"ğŸ˜­\",\n",
    "    u\"T\\.T\":\"ğŸ˜­\",\n",
    "    u\"QQ\":\"ğŸ˜­\",\n",
    "    u\"Q_Q\":\"ğŸ˜­\",\n",
    "    u\"\\(-\\.-\\)\":\"ğŸ˜\",\n",
    "    u\"\\(-_-\\)\":\"ğŸ˜\",\n",
    "    u\"\\(ä¸€ä¸€\\)\":\"ğŸ˜\",\n",
    "    u\"\\(ï¼›ä¸€_ä¸€\\)\":\"ğŸ˜\",\n",
    "    u\"\\(=_=\\)\":\"ğŸ˜©\",\n",
    "    u\"\\(=\\^\\Â·\\^=\\)\":\"ğŸ˜º\",\n",
    "    u\"\\(=\\^\\Â·\\Â·\\^=\\)\":\"ğŸ˜º\",\n",
    "    u\"=_\\^=\t\":\"ğŸ˜º\",\n",
    "    u\"\\(\\.\\.\\)\":\"ğŸ˜”\",\n",
    "    u\"\\(\\._\\.\\)\":\"ğŸ˜”\",\n",
    "    u\"\\(\\ãƒ»\\ãƒ»?\":\"ğŸ˜•\",\n",
    "    u\"\\(?_?\\)\":\"ğŸ˜•\",\n",
    "    u\">\\^_\\^<\":\"ğŸ˜ƒ\",\n",
    "    u\"<\\^!\\^>\":\"ğŸ˜ƒ\",\n",
    "    u\"\\^/\\^\":\"ğŸ˜ƒ\",\n",
    "    u\"\\ï¼ˆ\\*\\^_\\^\\*ï¼‰\" :\"ğŸ˜ƒ\",\n",
    "    u\"\\(\\^<\\^\\) \\(\\^\\.\\^\\)\":\"ğŸ˜ƒ\",\n",
    "    u\"\\(^\\^\\)\":\"ğŸ˜ƒ\",\n",
    "    u\"\\(\\^\\.\\^\\)\":\"ğŸ˜ƒ\",\n",
    "    u\"\\(\\^_\\^\\.\\)\":\"ğŸ˜ƒ\",\n",
    "    u\"\\(\\^_\\^\\)\":\"ğŸ˜ƒ\",\n",
    "    u\"\\(\\^\\^\\)\":\"ğŸ˜ƒ\",\n",
    "    u\"\\(\\^J\\^\\)\":\"ğŸ˜ƒ\",\n",
    "    u\"\\(\\*\\^\\.\\^\\*\\)\":\"ğŸ˜ƒ\",\n",
    "    u\"\\(\\^â€”\\^\\ï¼‰\":\"ğŸ˜ƒ\",\n",
    "    u\"\\(#\\^\\.\\^#\\)\":\"ğŸ˜ƒ\",\n",
    "    u\"\\ï¼ˆ\\^â€”\\^\\ï¼‰\":\"ğŸ‘‹\",\n",
    "    u\"\\(;_;\\)/~~~\":\"ğŸ‘‹\",\n",
    "    u\"\\(\\^\\.\\^\\)/~~~\":\"ğŸ‘‹\",\n",
    "    u\"\\(T_T\\)/~~~\":\"ğŸ‘‹\",\n",
    "    u\"\\(ToT\\)/~~~\":\"ğŸ‘‹\",\n",
    "    u\"\\(\\*\\^0\\^\\*\\)\":\"ğŸ˜\",\n",
    "    u\"\\(\\*_\\*\\)\":\"ğŸ˜\",\n",
    "    u\"\\(\\*_\\*;\":\"ğŸ˜\",\n",
    "    u\"\\(\\+_\\+\\) \\(@_@\\)\":\"ğŸ˜\",\n",
    "    u\"\\(\\*\\^\\^\\)v\":\"ğŸ˜‚\",\n",
    "    u\"\\(\\^_\\^\\)v\":\"ğŸ˜‚\",\n",
    "    u'\\(-\"-\\)':\"ğŸ˜“\",\n",
    "    u\"\\(ãƒ¼ãƒ¼;\\)\":\"ğŸ˜“\",\n",
    "    u\"\\(\\^0_0\\^\\)\":\"ğŸ˜\",\n",
    "    u\"\\(\\ï¼¾ï½–\\ï¼¾\\)\":\"ğŸ˜€\",\n",
    "    u\"\\(\\ï¼¾ï½•\\ï¼¾\\)\":\"ğŸ˜€\",\n",
    "    u\"\\(\\^\\)o\\(\\^\\)\":\"ğŸ˜€\",\n",
    "    u\"\\(\\^O\\^\\)\":\"ğŸ˜€\",\n",
    "    u\"\\(\\^o\\^\\)\":\"ğŸ˜€\",\n",
    "    u\"\\)\\^o\\^\\(\":\"ğŸ˜€\",\n",
    "    u\":O o_O\":\"ğŸ˜®\",\n",
    "    u\"o_0\":\"ğŸ˜®\",\n",
    "    u\"o\\.O\":\"ğŸ˜®\",\n",
    "    u\"\\(o\\.o\\)\":\"ğŸ˜®\",\n",
    "    u\"oO\":\"ğŸ˜®\",\n",
    "    u\"\\(\\*ï¿£mï¿£\\)\":\"ğŸ˜ \",\n",
    "    u\":â€‘)\":\"â˜ºï¸\",\n",
    "    u\":)\":\"â˜ºï¸\",\n",
    "    u\":-]\":\"â˜ºï¸\",\n",
    "    u\":]\":\"â˜ºï¸\",\n",
    "    u\":-3\":\"â˜ºï¸\",\n",
    "    u\":3\":\"â˜ºï¸\",\n",
    "    u\":->\":\"â˜ºï¸\",\n",
    "    u\":>\":\"â˜ºï¸\",\n",
    "    u\"8-)\":\"â˜ºï¸\",\n",
    "    u\":o)\":\"â˜ºï¸\",\n",
    "    u\":-}\":\"â˜ºï¸\",\n",
    "    u\":}\":\"â˜ºï¸\",\n",
    "    u\":-)\":\"â˜ºï¸\",\n",
    "    u\":c)\":\"â˜ºï¸\",\n",
    "    u\":^)\":\"â˜ºï¸\",\n",
    "    u\"=]\":\"â˜ºï¸\",\n",
    "    u\"=)\":\"â˜ºï¸\",\n",
    "    u\":â€‘D\":\"ğŸ˜ƒ\",\n",
    "    u\":D\":\"ğŸ˜ƒ\",\n",
    "    u\"8â€‘D\":\"ğŸ˜ƒ\",\n",
    "    u\"8D\":\"ğŸ˜ƒ\",\n",
    "    u\"Xâ€‘D\":\"ğŸ˜ƒ\",\n",
    "    u\"XD\":\"ğŸ˜ƒ\",\n",
    "    u\"=D\":\"ğŸ˜ƒ\",\n",
    "    u\"=3\":\"ğŸ˜ƒ\",\n",
    "    u\"B^D\":\"ğŸ˜ƒ\",\n",
    "    u\":-))\":\"ğŸ˜ƒ\",\n",
    "    u\":-(\":\"â˜¹ï¸\",\n",
    "    u\":â€‘(\":\"â˜¹ï¸\",\n",
    "    u\":(\":\"â˜¹ï¸\",\n",
    "    u\":â€‘c\":\"â˜¹ï¸\",\n",
    "    u\":c\":\"â˜¹ï¸\",\n",
    "    u\":â€‘<\":\"â˜¹ï¸\",\n",
    "    u\":<\":\"â˜¹ï¸\",\n",
    "    u\":â€‘[\":\"â˜¹ï¸\",\n",
    "    u\":[\":\"â˜¹ï¸\",\n",
    "    u\":-||\":\"â˜¹ï¸\",\n",
    "    u\">:[\":\"â˜¹ï¸\",\n",
    "    u\":{\":\"â˜¹ï¸\",\n",
    "    u\":@\":\"â˜¹ï¸\",\n",
    "    u\">:(\":\"â˜¹ï¸\",\n",
    "    u\":'â€‘(\":\"ğŸ˜­\",\n",
    "    u\":'(\":\"ğŸ˜­\",\n",
    "    u\":'â€‘)\":\"ğŸ˜ƒ\",\n",
    "    u\":')\":\"ğŸ˜ƒ\",\n",
    "    u\"Dâ€‘':\":\"ğŸ˜§\",\n",
    "    u\"D:<\":\"ğŸ˜¨\",\n",
    "    u\"D:\":\"ğŸ˜§\",\n",
    "    u\"D8\":\"ğŸ˜§\",\n",
    "    u\"D;\":\"ğŸ˜§\",\n",
    "    u\"D=\":\"ğŸ˜§\",\n",
    "    u\"DX\":\"ğŸ˜§\",\n",
    "    u\":â€‘O\":\"ğŸ˜®\",\n",
    "    u\":O\":\"ğŸ˜®\",\n",
    "    u\":â€‘o\":\"ğŸ˜®\",\n",
    "    u\":o\":\"ğŸ˜®\",\n",
    "    u\":-0\":\"ğŸ˜®\",\n",
    "    u\"8â€‘0\":\"ğŸ˜®\",\n",
    "    u\">:O\":\"ğŸ˜®\",\n",
    "    u\":-*\":\"ğŸ˜—\",\n",
    "    u\":*\":\"ğŸ˜—\",\n",
    "    u\":X\":\"ğŸ˜—\",\n",
    "    u\";â€‘)\":\"ğŸ˜‰\",\n",
    "    u\";)\":\"ğŸ˜‰\",\n",
    "    u\"*-)\":\"ğŸ˜‰\",\n",
    "    u\"*)\":\"ğŸ˜‰\",\n",
    "    u\";â€‘]\":\"ğŸ˜‰\",\n",
    "    u\";]\":\"ğŸ˜‰\",\n",
    "    u\";^)\":\"ğŸ˜‰\",\n",
    "    u\":â€‘,\":\"ğŸ˜‰\",\n",
    "    u\";D\":\"ğŸ˜‰\",\n",
    "    u\":â€‘P\":\"ğŸ˜›\",\n",
    "    u\":P\":\"ğŸ˜›\",\n",
    "    u\"Xâ€‘P\":\"ğŸ˜›\",\n",
    "    u\"XP\":\"ğŸ˜›\",\n",
    "    u\":â€‘Ã\":\"ğŸ˜›\",\n",
    "    u\":Ã\":\"ğŸ˜›\",\n",
    "    u\":b\":\"ğŸ˜›\",\n",
    "    u\"d:\":\"ğŸ˜›\",\n",
    "    u\"=p\":\"ğŸ˜›\",\n",
    "    u\">:P\":\"ğŸ˜›\",\n",
    "    u\":â€‘/\":\"ğŸ˜•\",\n",
    "    u\":/\":\"ğŸ˜•\",\n",
    "    u\":-[.]\":\"ğŸ˜•\",\n",
    "    u\">:[(\\)]\":\"ğŸ˜•\",\n",
    "    u\">:/\":\"ğŸ˜•\",\n",
    "    u\":[(\\)]\":\"ğŸ˜•\",\n",
    "    u\"=/\":\"ğŸ˜•\",\n",
    "    u\"=[(\\)]\":\"ğŸ˜•\",\n",
    "    u\":L\":\"ğŸ˜•\",\n",
    "    u\"=L\":\"ğŸ˜•\",\n",
    "    u\":S\":\"ğŸ˜•\",\n",
    "    u\":â€‘|\":\"ğŸ˜\",\n",
    "    u\":|\":\"ğŸ˜\",\n",
    "    u\":$\":\"ğŸ˜³\",\n",
    "    u\":â€‘x\":\"ğŸ¤\",\n",
    "    u\":x\":\"ğŸ¤\",\n",
    "    u\":â€‘#\":\"ğŸ¤\",\n",
    "    u\":#\":\"ğŸ¤\",\n",
    "    u\":â€‘&\":\"ğŸ¤\",\n",
    "    u\":&\":\"ğŸ¤\",\n",
    "    u\"O:â€‘)\":\"ğŸ˜‡\",\n",
    "    u\"O:)\":\"ğŸ˜‡\",\n",
    "    u\"0:â€‘3\":\"ğŸ˜‡\",\n",
    "    u\"0:3\":\"ğŸ˜‡\",\n",
    "    u\"0:â€‘)\":\"ğŸ˜‡\",\n",
    "    u\"0:)\":\"ğŸ˜‡\",\n",
    "    u\":â€‘b\":\"ğŸ˜›\",\n",
    "    u\"0;^)\":\"ğŸ˜‡\",\n",
    "    u\">:â€‘)\":\"ğŸ˜ˆ\",\n",
    "    u\">:)\":\"ğŸ˜ˆ\",\n",
    "    u\"}:â€‘)\":\"ğŸ˜ˆ\",\n",
    "    u\"}:)\":\"ğŸ˜ˆ\",\n",
    "    u\"3:â€‘)\":\"ğŸ˜ˆ\",\n",
    "    u\"3:)\":\"ğŸ˜ˆ\",\n",
    "    u\">;)\":\"ğŸ˜ˆ\",\n",
    "    u\"|;â€‘)\":\"ğŸ˜\",\n",
    "    u\"|â€‘O\":\"ğŸ˜\",\n",
    "    u\":â€‘J\":\"ğŸ˜\",\n",
    "    u\"%â€‘)\":\"ğŸ˜µ\",\n",
    "    u\"%)\":\"ğŸ˜µ\",\n",
    "    u\":-###..\":\"ğŸ¤’\",\n",
    "    u\":###..\":\"ğŸ¤’\",\n",
    "    u\"(>_<)\":\"ğŸ˜£\",\n",
    "    u\"(>_<)>\":\"ğŸ˜£\",\n",
    "    u\"(';')\":\"Baby\",\n",
    "    u\"(^^>``\":\"ğŸ˜“\",\n",
    "    u\"(^_^;)\":\"ğŸ˜“\",\n",
    "    u\"(-_-;)\":\"ğŸ˜“\",\n",
    "    u\"(~_~;) (ãƒ».ãƒ»;)\":\"ğŸ˜“\",\n",
    "    u\"(-_-)zzz\":\"ğŸ˜´\",\n",
    "    u\"(^_-)\":\"ğŸ˜‰\",\n",
    "    u\"((+_+))\":\"ğŸ˜•\",\n",
    "    u\"(+o+)\":\"ğŸ˜•\",\n",
    "    u\"^_^\":\"ğŸ˜ƒ\",\n",
    "    u\"(^_^)/\":\"ğŸ˜ƒ\",\n",
    "    u\"(^O^)ï¼\":\"ğŸ˜ƒ\",\n",
    "    u\"(^o^)ï¼\":\"ğŸ˜ƒ\",\n",
    "    u\"(__)\":\"ğŸ™‡\",\n",
    "    u\"_(._.)_\":\"ğŸ™‡\",\n",
    "    u\"<(_ _)>\":\"ğŸ™‡\",\n",
    "    u\"<m(__)m>\":\"ğŸ™‡\",\n",
    "    u\"m(__)m\":\"ğŸ™‡\",\n",
    "    u\"m(_ _)m\":\"ğŸ™‡\",\n",
    "    u\"('_')\":\"ğŸ˜­\",\n",
    "    u\"(/_;)\":\"ğŸ˜­\",\n",
    "    u\"(T_T) (;_;)\":\"ğŸ˜­\",\n",
    "    u\"(;_;\":\"ğŸ˜­\",\n",
    "    u\"(;_:)\":\"ğŸ˜­\",\n",
    "    u\"(;O;)\":\"ğŸ˜­\",\n",
    "    u\"(:_;)\":\"ğŸ˜­\",\n",
    "    u\"(ToT)\":\"ğŸ˜­\",\n",
    "    u\";_;\":\"ğŸ˜­\",\n",
    "    u\";-;\":\"ğŸ˜­\",\n",
    "    u\";n;\":\"ğŸ˜­\",\n",
    "    u\";;\":\"ğŸ˜­\",\n",
    "    u\"Q.Q\":\"ğŸ˜­\",\n",
    "    u\"T.T\":\"ğŸ˜­\",\n",
    "    u\"QQ\":\"ğŸ˜­\",\n",
    "    u\"Q_Q\":\"ğŸ˜­\",\n",
    "    u\"(-.-)\":\"ğŸ˜\",\n",
    "    u\"(-_-)\":\"ğŸ˜\",\n",
    "    u\"(ä¸€ä¸€)\":\"ğŸ˜\",\n",
    "    u\"(ï¼›ä¸€_ä¸€)\":\"ğŸ˜\",\n",
    "    u\"(=_=)\":\"ğŸ˜©\",\n",
    "    u\"(=^Â·^=)\":\"ğŸ˜º\",\n",
    "    u\"(=^Â·Â·^=)\":\"ğŸ˜º\",\n",
    "    u\"=_^= \":\"ğŸ˜º\",\n",
    "    u\"(..)\":\"ğŸ˜”\",\n",
    "    u\"(._.)\":\"ğŸ˜”\",\n",
    "    u\"(ãƒ»ãƒ»?\":\"ğŸ˜•\",\n",
    "    u\"(?_?)\":\"ğŸ˜•\",\n",
    "    u\">^_^<\":\"ğŸ˜ƒ\",\n",
    "    u\"<^!^>\":\"ğŸ˜ƒ\",\n",
    "    u\"^/^\":\"ğŸ˜ƒ\",\n",
    "    u\"ï¼ˆ*^_^*ï¼‰\" :\"ğŸ˜ƒ\",\n",
    "    u\"(^<^) (^.^)\":\"ğŸ˜ƒ\",\n",
    "    u\"(^^)\":\"ğŸ˜ƒ\",\n",
    "    u\"(^.^)\":\"ğŸ˜ƒ\",\n",
    "    u\"(^_^.)\":\"ğŸ˜ƒ\",\n",
    "    u\"(^_^)\":\"ğŸ˜ƒ\",\n",
    "    u\"(^^)\":\"ğŸ˜ƒ\",\n",
    "    u\"(^J^)\":\"ğŸ˜ƒ\",\n",
    "    u\"(*^.^*)\":\"ğŸ˜ƒ\",\n",
    "    u\"(^â€”^ï¼‰\":\"ğŸ˜ƒ\",\n",
    "    u\"(#^.^#)\":\"ğŸ˜ƒ\",\n",
    "    u\"ï¼ˆ^â€”^ï¼‰\":\"ğŸ‘‹\",\n",
    "    u\"(;_;)/~~~\":\"ğŸ‘‹\",\n",
    "    u\"(^.^)/~~~\":\"ğŸ‘‹\",\n",
    "    u\"(-_-)/~~~ ($Â·Â·)/~~~\":\"ğŸ‘‹\",\n",
    "    u\"(T_T)/~~~\":\"ğŸ‘‹\",\n",
    "    u\"(ToT)/~~~\":\"ğŸ‘‹\",\n",
    "    u\"(*^0^*)\":\"ğŸ˜\",\n",
    "    u\"(*_*)\":\"ğŸ˜\",\n",
    "    u\"(*_*;\":\"ğŸ˜\",\n",
    "    u\"(+_+) (@_@)\":\"ğŸ˜\",\n",
    "    u\"(*^^)v\":\"ğŸ˜‚\",\n",
    "    u\"(^_^)v\":\"ğŸ˜‚\",\n",
    "    u'(-\"-)':\"ğŸ˜“\",\n",
    "    u\"(ãƒ¼ãƒ¼;)\":\"ğŸ˜“\",\n",
    "    u\"(^0_0^)\":\"ğŸ˜\",\n",
    "    u\"(ï¼¾ï½–ï¼¾)\":\"ğŸ˜€\",\n",
    "    u\"(ï¼¾ï½•ï¼¾)\":\"ğŸ˜€\",\n",
    "    u\"(^)o(^)\":\"ğŸ˜€\",\n",
    "    u\"(^O^)\":\"ğŸ˜€\",\n",
    "    u\"(^o^)\":\"ğŸ˜€\",\n",
    "    u\")^o^(\":\"ğŸ˜€\",\n",
    "    u\":O o_O\":\"ğŸ˜®\",\n",
    "    u\"o_0\":\"ğŸ˜®\",\n",
    "    u\"o.O\":\"ğŸ˜®\",\n",
    "    u\"(o.o)\":\"ğŸ˜®\",\n",
    "    u\"oO\":\"ğŸ˜®\",\n",
    "}\n",
    "\n",
    "\n",
    "def str2emoji(tweet):\n",
    "\t\n",
    "\tfor pos,ej in enumerate(tweet):\n",
    "\t\tif ej in emojis:\n",
    "\t\t\ttweet[pos]=emojis[ej]\n",
    "\treturn tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjpS6y1RKeeZ"
   },
   "outputs": [],
   "source": [
    "def norm_tweet(tweet):\n",
    "  tweet = re.sub(r\"\\\\u2019\", \"'\", tweet)\n",
    "  tweet = re.sub(r\"\\\\u002c\", \",\", tweet)\n",
    "  tweet=' '.join(str2emoji(unidecode(tweet).lower().split()))\n",
    "  tweet = re.sub(r\"\\'ve\", \" have\", tweet)\n",
    "  tweet = re.sub(r\" can\\'t\", \" cannot\", tweet)\n",
    "  tweet = re.sub(r\"n\\'t\", \" not\", tweet)\n",
    "  tweet = re.sub(r\"\\'re\", \" are\", tweet)\n",
    "  tweet = re.sub(r\"\\'d\", \" would\", tweet)\n",
    "  tweet = re.sub(r\"\\'ll\", \" will\", tweet)\n",
    "  tweet = re.sub(r\"\\'s\", \"\", tweet)\n",
    "  tweet = re.sub(r\"\\'n\", \"\", tweet)\n",
    "  tweet = re.sub(r\"\\'m\", \" am\", tweet)\n",
    "  tweet = re.sub(r\"@\\w+\", r' ',tweet)\n",
    "  tweet = re.sub(r\"#\\w+\", r' ',tweet)\n",
    "  tweet = re.sub(r\"[.]+\",\" \",tweet)\n",
    "  #T = tokenizer.TweetTokenizer()\n",
    "  tweet = T.tokenize(tweet)\n",
    "  #tweet = [lemmatizer.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v']  else lemmatizer.lemmatize(i) for i,j in pos_tag(tknzr.tokenize(tweet))]\n",
    "  tweet = [ i for i in tweet if (i not in stopwords) and (i not in string.punctuation ) ]\n",
    "  #tweet = ' '.join(tweet)\n",
    "  return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Rv6ih5wKoHV"
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(data):\n",
    "  data['data'] = data['data'].apply(norm_tweet)\n",
    "  print(data['sentiment'].dtypes)\n",
    "  if data['sentiment'].dtypes not in [np.int64]:\n",
    "    data['sentiment']=data['sentiment'].apply(value_sentiment)\n",
    "  return data['data'],data['sentiment'],data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zxXHdW0IODWx"
   },
   "outputs": [],
   "source": [
    "def model1(x_train_3, y_train_3,x_val_3, y_val_3, embedding_layer):\n",
    "\n",
    "\tmodel1 = Sequential()\n",
    "\tmodel1.add(embedding_layer)\n",
    "\tmodel1.add(LSTM(32))\n",
    "\tmodel1.add(Dropout(0.2))\n",
    "\tmodel1.add(Dense(32, activation='relu'))\n",
    "\tmodel1.add(Dropout(0.2))\n",
    "\tmodel1.add(Dense(3, activation='softmax'))\n",
    "\tmodel1.compile(loss='categorical_crossentropy',\n",
    "\t\t\t      optimizer='Adam',\n",
    "\t\t\t      metrics=['acc'])\n",
    "\tmodel1.summary()\n",
    "\thistory=model1.fit(x_train_3, y_train_3, validation_data=(x_val_3, y_val_3),epochs=6, batch_size=50)\n",
    "\tmodel1.save(\"./model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sdLO3C6WODMT"
   },
   "outputs": [],
   "source": [
    "def model2(x_train_3, y_train_3,x_val_3, y_val_3, embedding_layer,epochs, batch_size):\n",
    "\tmodel2 = Sequential()\n",
    "\tmodel2.add(embedding_layer)\n",
    "\tmodel2.add(GRU(32))\n",
    "\tmodel2.add(Dropout(0.2))\n",
    "\tmodel2.add(Dense(3, activation='softmax'))\n",
    "\tmodel2.compile(loss='categorical_crossentropy',\n",
    "\t\t\t      optimizer='rmsprop',\n",
    "\t\t\t      metrics=['acc'])\n",
    "\tmodel2.summary()\n",
    "\thistory=model2.fit(x_train_3, y_train_3, validation_data=(x_val_3, y_val_3),epochs=epochs, batch_size=batch_size)\n",
    "\tmodel2.save(\"./model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQiBIkDmKoEU"
   },
   "outputs": [],
   "source": [
    "#Path of datas\n",
    "data_train_3 =  \"train_1_1.csv\"\n",
    "data_train_7 =  \"train_3_3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FezwSR_SLp4p"
   },
   "outputs": [],
   "source": [
    "#Load Data\n",
    "data_train_3= pd.read_csv(data_train_3,sep='\\t',names=['id','sentiment','data'])\n",
    "data_train_7= pd.read_csv(data_train_7,sep='\\t',names=['id','sentiment','data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CTmWa7BuKoBy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# Apply the preprocessiog on the data\n",
    "# Normalize the tweets\n",
    "tweets_train_3, sentiments_train_3,data_train_3 = data_preprocessing(data_train_3)\n",
    "tweets_train_7, sentiments_train_7,data_train_7 = data_preprocessing(data_train_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rlA-OcLQLKwi"
   },
   "outputs": [],
   "source": [
    "all_tweet = tweets_train_3.append(tweets_train_7)\n",
    "tokenizer = Tokenizer(filters=' ')\n",
    "tokenizer.fit_on_texts(all_tweet)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3KWoHuF5MvAZ"
   },
   "outputs": [],
   "source": [
    "sequences_train_3 = tokenizer.texts_to_sequences(tweets_train_3)\n",
    "sequences_train_7 = tokenizer.texts_to_sequences(tweets_train_7)\n",
    "sequences = sequences_train_3 + sequences_train_7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rER1ZxaLgd1"
   },
   "outputs": [],
   "source": [
    "#Seek the longuest Tweet\n",
    "#To Apply a Padding\n",
    "MAX_SEQUENCE_LENGTH = 0\n",
    "for elt in sequences:\n",
    "\tif len(elt) > MAX_SEQUENCE_LENGTH:\n",
    "\t\tMAX_SEQUENCE_LENGTH = len(elt)\n",
    "  \n",
    "data_train_3 = pad_sequences(sequences_train_3, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_train_7 = pad_sequences(sequences_train_7, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GL0k6uf1Lga3"
   },
   "outputs": [],
   "source": [
    "indices_train_3 = np.arange(data_train_3.shape[0])\n",
    "data_train_3 = data_train_3[indices_train_3]\n",
    "\n",
    "indices_train_7 = np.arange(data_train_7.shape[0])\n",
    "data_train_7 = data_train_7[indices_train_7]\n",
    "\n",
    "labels_train_3 = to_categorical(np.asarray(sentiments_train_3), 3)\n",
    "labels_train_3 = labels_train_3[indices_train_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dEFq7QZbLgSk"
   },
   "outputs": [],
   "source": [
    "nb_words=len(word_index)+1\n",
    "EMBEDDING_DIM=300\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90yb26nXNvnt"
   },
   "outputs": [],
   "source": [
    "oov=[]\n",
    "oov.append((np.random.rand(EMBEDDING_DIM)) - 1.0)\n",
    "oov = oov / np.linalg.norm(oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8X5fM9nSNvj5"
   },
   "outputs": [],
   "source": [
    "for word, i in word_index.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embedding_matrix[i] = word2vec.word_vec(word)\n",
    "    else:\n",
    "        embedding_matrix[i] = oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofA7BZ1UNvgD"
   },
   "outputs": [],
   "source": [
    "split_idx = int(len(data_train_3)*0.70)\n",
    "x_train_3, x_val_3 = data_train_3[:split_idx], data_train_3[split_idx:]\n",
    "y_train_3, y_val_3 = labels_train_3 [:split_idx], labels_train_3[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGqBPaa-Nvb8"
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False, name='embedding_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wc_MJrSoNvYo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, 31, 300)           18438300  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 18,482,079\n",
      "Trainable params: 43,779\n",
      "Non-trainable params: 18,438,300\n",
      "_________________________________________________________________\n",
      "Train on 35233 samples, validate on 15100 samples\n",
      "Epoch 1/6\n",
      "35233/35233 [==============================] - 10s 274us/step - loss: 0.8336 - acc: 0.6108 - val_loss: 0.8145 - val_acc: 0.6145\n",
      "Epoch 2/6\n",
      "35233/35233 [==============================] - 9s 267us/step - loss: 0.7590 - acc: 0.6603 - val_loss: 0.8519 - val_acc: 0.5868\n",
      "Epoch 3/6\n",
      "35233/35233 [==============================] - 9s 265us/step - loss: 0.7351 - acc: 0.6724 - val_loss: 0.8126 - val_acc: 0.6144\n",
      "Epoch 4/6\n",
      "35233/35233 [==============================] - 9s 265us/step - loss: 0.7198 - acc: 0.6821 - val_loss: 0.8096 - val_acc: 0.6162\n",
      "Epoch 5/6\n",
      "35233/35233 [==============================] - 9s 266us/step - loss: 0.7015 - acc: 0.6903 - val_loss: 0.7923 - val_acc: 0.6221\n",
      "Epoch 6/6\n",
      "35233/35233 [==============================] - 9s 264us/step - loss: 0.6860 - acc: 0.7002 - val_loss: 0.8309 - val_acc: 0.6109\n"
     ]
    }
   ],
   "source": [
    "model1(x_train_3, y_train_3,x_val_3, y_val_3, embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtZU5RcnNvS2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, 31, 300)           18438300  \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                31968     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 18,470,367\n",
      "Trainable params: 32,067\n",
      "Non-trainable params: 18,438,300\n",
      "_________________________________________________________________\n",
      "Train on 35233 samples, validate on 15100 samples\n",
      "Epoch 1/6\n",
      "35233/35233 [==============================] - 10s 280us/step - loss: 0.8374 - acc: 0.6112 - val_loss: 0.8103 - val_acc: 0.6108\n",
      "Epoch 2/6\n",
      "35233/35233 [==============================] - 9s 267us/step - loss: 0.7539 - acc: 0.6641 - val_loss: 0.7940 - val_acc: 0.6241\n",
      "Epoch 3/6\n",
      "35233/35233 [==============================] - 10s 273us/step - loss: 0.7332 - acc: 0.6753 - val_loss: 0.8172 - val_acc: 0.6145\n",
      "Epoch 4/6\n",
      "35233/35233 [==============================] - 9s 263us/step - loss: 0.7175 - acc: 0.6814 - val_loss: 0.8082 - val_acc: 0.6203\n",
      "Epoch 5/6\n",
      "35233/35233 [==============================] - 9s 264us/step - loss: 0.7037 - acc: 0.6899 - val_loss: 0.8190 - val_acc: 0.6164\n",
      "Epoch 6/6\n",
      "35233/35233 [==============================] - 9s 264us/step - loss: 0.6889 - acc: 0.6955 - val_loss: 0.7952 - val_acc: 0.6269\n"
     ]
    }
   ],
   "source": [
    "model2(x_train_3, y_train_3,x_val_3, y_val_3, embedding_layer, 6, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Af6C8eMXNvOF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4      -2\n",
      "       ..\n",
      "1625    3\n",
      "1626   -2\n",
      "1627    1\n",
      "1628    0\n",
      "1629   -2\n",
      "Name: sentiment, Length: 1630, dtype: int64 0                             [yeah, â˜º, ï¸, playing, well]\n",
      "1       [least, guy, trying, discourage, anymore, want...\n",
      "2       [uplift, still, discouraged, means, listening,...\n",
      "3                              [age, heyday, blood, tame]\n",
      "4       [embarrassed, saw, us, like, knvfkkjg, thinks,...\n",
      "                              ...                        \n",
      "1625       [idk, help, someone, smile, comes, lips, n, n]\n",
      "1626    [think, leep, favorite, get, dark, maybe, inso...\n",
      "1627                   [amelia, want, sarah, v, grateful]\n",
      "1628                                  [lack, makes, n, n]\n",
      "1629                   [james, clapper, cary, disturbing]\n",
      "Name: data, Length: 1630, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sentiments_train_7, tweets_train_7)\n",
    "labels_train_7 = to_categorical(np.asarray(sentiments_train_7), 7)\n",
    "labels_train_7 = labels_train_7[indices_train_7]\n",
    "\n",
    "split_idx = int(len(data_train_7)*0.85)\n",
    "x_train_7, x_val_7 = data_train_7[:split_idx], data_train_7[split_idx:]\n",
    "y_train_7, y_val_7 = labels_train_7 [:split_idx], labels_train_7[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJAVpUubpzrY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, 31, 300)           18438300  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 18,482,079\n",
      "Trainable params: 43,779\n",
      "Non-trainable params: 18,438,300\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, 31, 300)           18438300  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 99        \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 64)                9664      \n",
      "_________________________________________________________________\n",
      "dense3 (Dense)               (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 18,482,079\n",
      "Trainable params: 43,779\n",
      "Non-trainable params: 18,438,300\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beuvry_j/.local/lib/python3.7/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1385 samples, validate on 245 samples\n",
      "Epoch 1/11\n",
      "1385/1385 [==============================] - 1s 575us/step - loss: 1.8115 - accuracy: 0.3040 - val_loss: 1.7134 - val_accuracy: 0.2735\n",
      "Epoch 2/11\n",
      "1385/1385 [==============================] - 0s 315us/step - loss: 1.6584 - accuracy: 0.3437 - val_loss: 1.6497 - val_accuracy: 0.2816\n",
      "Epoch 3/11\n",
      "1385/1385 [==============================] - 0s 319us/step - loss: 1.6028 - accuracy: 0.3545 - val_loss: 1.6366 - val_accuracy: 0.2939\n",
      "Epoch 4/11\n",
      "1385/1385 [==============================] - 0s 315us/step - loss: 1.5597 - accuracy: 0.3697 - val_loss: 1.6209 - val_accuracy: 0.3755\n",
      "Epoch 5/11\n",
      "1385/1385 [==============================] - 0s 316us/step - loss: 1.5282 - accuracy: 0.3776 - val_loss: 1.6350 - val_accuracy: 0.3510\n",
      "Epoch 6/11\n",
      "1385/1385 [==============================] - 0s 308us/step - loss: 1.4929 - accuracy: 0.4058 - val_loss: 1.6261 - val_accuracy: 0.3592\n",
      "Epoch 7/11\n",
      "1385/1385 [==============================] - 0s 317us/step - loss: 1.4641 - accuracy: 0.4065 - val_loss: 1.6385 - val_accuracy: 0.3714\n",
      "Epoch 8/11\n",
      "1385/1385 [==============================] - 0s 303us/step - loss: 1.4319 - accuracy: 0.4181 - val_loss: 1.6523 - val_accuracy: 0.3673\n",
      "Epoch 9/11\n",
      "1385/1385 [==============================] - 0s 302us/step - loss: 1.4133 - accuracy: 0.4289 - val_loss: 1.6749 - val_accuracy: 0.3796\n",
      "Epoch 10/11\n",
      "1385/1385 [==============================] - 0s 311us/step - loss: 1.3917 - accuracy: 0.4448 - val_loss: 1.6761 - val_accuracy: 0.3755\n",
      "Epoch 11/11\n",
      "1385/1385 [==============================] - 0s 309us/step - loss: 1.3541 - accuracy: 0.4527 - val_loss: 1.6926 - val_accuracy: 0.3673\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.load_model(\"./model1.h5\")\n",
    "model.summary()\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model.add(Dense(150,activation='relu',name='dense1'))\n",
    "model.add(Dense(64,activation='relu',name='dense2'))\n",
    "model.add(Dense(7,activation='softmax',name='dense3'))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train_7, y_train_7,   validation_data=(x_val_7,y_val_7), epochs=11, batch_size=50)\n",
    "model.save(\"./model3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e02yEAVrNvKm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "corpora_test_7=\"./train_3_3.csv\"\n",
    "corpora_test_7= pd.read_csv(corpora_test_7,sep='\\t',names=['id','sentiment','data'])\n",
    "\n",
    "tweets_test_7,sentiments_test_3,corpora_test_7 =  data_preprocessing(corpora_test_7)\n",
    "sequences_test_7 = tokenizer.texts_to_sequences(tweets_test_7)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
